# EDGY

## Introduction
```
This repo provides the code for "Privacy-preserving Voice Analysis via Disentangled Representations" paper.
```
![GitHub Logo](/images/Potential_Attacks.png)

As shown in this figure, Voice User Interfaces (VUIs) are increasingly popular and built into smartphones, home assistants, and Internet of Things (IoT) devices. Despite offering an always-on convenient user experience, VUIs raise new security and privacy concerns for their users. 
In this paper, we focus on attribute inference attacks in the speech domain, demonstrating the potential for an attacker to accurately infer a target user's sensitive and private attributes (e.g. their emotion, sex, or health status) from deep acoustic models. To defend against this class of attacks, we design, implement, and evaluate a user-configurable, privacy-aware framework for optimizing speech-related data sharing mechanisms.

## Table of Contents
```
* Training
* Item 2
  * Item 2a
  * Item 2b
```

## Requirements
```
Hello
```

## Download Dataset and Training
```
Details under **Training Folder**
```

## Usage
```
Hello
```

## Cite
```
If you find this work useful, please cite us.
@misc{aloufi2020privacypreserving,
    title={Privacy-preserving Voice Analysis via Disentangled Representations},
    author={Ranya Aloufi and Hamed Haddadi and David Boyle},
    year={2020},
    eprint={2007.15064},
    archivePrefix={arXiv},
    primaryClass={eess.AS}
}
```

## Contributing
```
This project welcomes contributions and suggestions. 
Please contact **ra6018@imperial.ac.uk** with any additional questions or comments.
```


